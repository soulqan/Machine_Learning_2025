{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5z9i3g9z2sK7p3CcUTFJM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soulqan/2341720191_ML_2025/blob/main/JS13_Praktikum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Praktikum 1"
      ],
      "metadata": {
        "id": "hSQjQRTX1kQl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0yd_ZRq9gq9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b2be4e-8c8c-4c91-fe3f-453fdc0118ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2858609574691293\n",
            "Epoch 1000, Loss: 0.24992788983786587\n",
            "Epoch 2000, Loss: 0.24708653183985724\n",
            "Epoch 3000, Loss: 0.22397183391992148\n",
            "Epoch 4000, Loss: 0.18352842615819975\n",
            "Epoch 5000, Loss: 0.06086628910855657\n",
            "Epoch 6000, Loss: 0.016429769760676165\n",
            "Epoch 7000, Loss: 0.008466177474943538\n",
            "Epoch 8000, Loss: 0.005533046185646509\n",
            "Epoch 9000, Loss: 0.00405695421162467\n",
            "Prediksi:\n",
            "[[0.06234634]\n",
            " [0.9482167 ]\n",
            " [0.94429026]\n",
            " [0.05526473]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ],
      "metadata": {
        "id": "uszmsG_7q7M8",
        "outputId": "4cf90b90-5f79-4ab9-b341-fa5948234b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.24841371336177276\n",
            "Epoch 1000, Loss: 0.20277905596202914\n",
            "Epoch 2000, Loss: 0.1635686660705854\n",
            "Epoch 3000, Loss: 0.14568069289946073\n",
            "Epoch 4000, Loss: 0.13797247388587094\n",
            "Epoch 5000, Loss: 0.1340970539259281\n",
            "Epoch 6000, Loss: 0.13186487659656584\n",
            "Epoch 7000, Loss: 0.1304476852102731\n",
            "Epoch 8000, Loss: 0.12948204402026217\n",
            "Epoch 9000, Loss: 0.1287883025764806\n",
            "Prediksi:\n",
            "[[0.04242313]\n",
            " [0.94382206]\n",
            " [0.49823494]\n",
            " [0.50631452]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Epoch | Loss (Hidden = 2 Neuron) | Loss (Hidden = 3 Neuron) |\n",
        "|-------|----------------------------|----------------------------|\n",
        "| 0     | 0.2858609574691293         | 0.24841371336177276        |\n",
        "| 1000  | 0.24992788983786587        | 0.20277905596202914        |\n",
        "| 2000  | 0.24708653183985724        | 0.1635686660705854         |\n",
        "| 3000  | 0.22397183391992148        | 0.14568069289946073        |\n",
        "| 4000  | 0.18352842615819975        | 0.13797247388587094        |\n",
        "| 5000  | 0.06086628910855657        | 0.1340970539259281         |\n",
        "| 6000  | 0.016429769760676165       | 0.13186487659656584        |\n",
        "| 7000  | 0.008466177474943538       | 0.1304476852102731         |\n",
        "| 8000  | 0.005533046185646509       | 0.12948204402026217        |\n",
        "| 9000  | 0.00405695421162467        | 0.1287883025764806         |\n",
        "\n",
        "Hidden 2 neuron → awalnya loss lebih besar tetapi menurun drastis dan berhasil mempelajari XOR dengan baik.\n",
        "\n",
        "Hidden 3 neuron → loss menurun, tetapi training tidak menemukan solusi XOR (neuron 3 kurang optimal dengan weight random awal tersebut)."
      ],
      "metadata": {
        "id": "kHU0L1a0tCE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tugas\n"
      ],
      "metadata": {
        "id": "kJDy-fxHy5KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Aktivasi\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "losses = []\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = relu(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backprop\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(z1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        losses.append((epoch, loss))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "print(\"Prediksi ReLU:\")\n",
        "print(a2)\n"
      ],
      "metadata": {
        "id": "GTtAGsCRy6mK",
        "outputId": "ee8a92d8-701c-4b3b-d28e-9328e0b31f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.21385577807110795\n",
            "Epoch 1000, Loss: 0.004886492462497567\n",
            "Epoch 2000, Loss: 0.0017250561421684888\n",
            "Epoch 3000, Loss: 0.0010112517491786626\n",
            "Epoch 4000, Loss: 0.0007060382427301699\n",
            "Epoch 5000, Loss: 0.0005391512713126904\n",
            "Epoch 6000, Loss: 0.00043441904547456163\n",
            "Epoch 7000, Loss: 0.0003628589041289503\n",
            "Epoch 8000, Loss: 0.0003109981048542922\n",
            "Epoch 9000, Loss: 0.0002718178650006128\n",
            "Prediksi ReLU:\n",
            "[[0.01965877]\n",
            " [0.99015145]\n",
            " [0.99026304]\n",
            " [0.01965858]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perbandingan Loss XOR (Sigmoid vs ReLU)\n",
        "\n",
        "| Epoch | Sigmoid (2 Neuron) | Sigmoid (3 Neuron) | ReLU (3 Neuron) |\n",
        "|-------|----------------------|----------------------|------------------|\n",
        "| 0     | 0.2858609574691293   | 0.24841371336177276  | 0.2984166617226946 |\n",
        "| 1000  | 0.24992788983786587  | 0.20277905596202914  | 0.1263525736522512 |\n",
        "| 2000  | 0.24708653183985724  | 0.1635686660705854   | 0.1254420887788794 |\n",
        "| 3000  | 0.22397183391992148  | 0.14568069289946073  | 0.12524743534526797 |\n",
        "| 4000  | 0.18352842615819975  | 0.13797247388587094  | 0.12516423460375903 |\n",
        "| 5000  | 0.06086628910855657  | 0.1340970539259281   | 0.12512533267096526 |\n",
        "| 6000  | 0.016429769760676165 | 0.13186487659656584  | 0.12510178710591524 |\n",
        "| 7000  | 0.008466177474943538 | 0.1304476852102731   | 0.12508330777294907 |\n",
        "| 8000  | 0.005533046185646509 | 0.12948204402026217  | 0.1250745868396193 |\n",
        "| 9000  | 0.00405695421162467  | 0.1287883025764806   | 0.12506325476662747 |\n",
        "\n",
        "\n",
        "hasil training ReLU tidak sepenuhnya konvergen untuk XOR, hanya sebagian berhasil (output untuk input (1,0) masih 0.49). Loss juga stagnan di sekitar 0.125, artinya jaringan tidak break symmetry."
      ],
      "metadata": {
        "id": "vtD209ITz6O3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Praktikum 2\n"
      ],
      "metadata": {
        "id": "CyBChLfz1oU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Bangun model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi: {acc}\")"
      ],
      "metadata": {
        "id": "e8szO_We1qE4",
        "outputId": "7d43113e-80c7-4597-dfaa-f59263191da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3524 - loss: 1.3382\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2883 - loss: 1.3013 \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1892 - loss: 1.1956 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3014 - loss: 1.1308 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3005 - loss: 1.1289 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3380 - loss: 1.0907 \n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3720 - loss: 1.0789 \n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3263 - loss: 1.0802 \n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3401 - loss: 1.0631 \n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3604 - loss: 1.0444 \n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3229 - loss: 1.0502 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3534 - loss: 1.0434 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3767 - loss: 1.0275 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3855 - loss: 1.0107 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4468 - loss: 1.0152 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4207 - loss: 0.9767 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3796 - loss: 0.9984 \n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4472 - loss: 1.0041 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4948 - loss: 0.9649 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3587 - loss: 0.9825 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4161 - loss: 0.9537 \n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3903 - loss: 0.9382 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3586 - loss: 0.9432 \n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4583 - loss: 0.9107 \n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3829 - loss: 0.9005 \n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3947 - loss: 0.8865 \n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3530 - loss: 0.8768 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4042 - loss: 0.8614 \n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4611 - loss: 0.8315 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3526 - loss: 0.8568 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5313 - loss: 0.7814 \n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7830 - loss: 0.7451 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.7354 \n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8418 - loss: 0.6993 \n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.6967 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.6033 \n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8592 - loss: 0.5915 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.5761 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8948 - loss: 0.5154 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.5198 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.4684 \n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9223 - loss: 0.4537 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9588 - loss: 0.4428 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.3997 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.3876 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9646 - loss: 0.3749 \n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.3898 \n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.3444 \n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 0.3540 \n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9490 - loss: 0.3299 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9333 - loss: 0.3302\n",
            "Akurasi: 0.9333333373069763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tugas 2"
      ],
      "metadata": {
        "id": "YfXLW1JD-dyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model yang di bangun**\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "    tf.keras.layers.Dense(12, activation='relu', input_shape=(4,)),\n",
        "\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "\n",
        "])\n",
        "\n",
        "Akurasi meningkat dari 0.93 menjadi 0.96 karena penambahan jumlah neuron membuat model memiliki kapasitas lebih besar untuk mempelajari dan merepresentasikan pola data. Dengan model yang lebih kompleks, jaringan dapat mengekstraksi fitur secara lebih efektif. Namun, jumlah neuron yang terlalu banyak dapat meningkatkan risiko overfitting."
      ],
      "metadata": {
        "id": "7InQAsUv-fb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Bangun model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(12, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi: {acc}\")"
      ],
      "metadata": {
        "id": "LMcRKvrF8ueK",
        "outputId": "9cca6773-d986-4717-e23e-59de016c3702",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6783 - loss: 3.2871\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6630 - loss: 2.7258 \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7295 - loss: 1.8042 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6299 - loss: 1.8949 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6667 - loss: 1.3098 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6770 - loss: 1.0274 \n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6690 - loss: 0.8523 \n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6332 - loss: 0.7712 \n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 0.7133 \n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.5869 \n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7122 - loss: 0.5440 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.4958 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9180 - loss: 0.4666 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9330 - loss: 0.4427 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9619 - loss: 0.4498 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.4190 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.3869 \n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.3580 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.3795 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.3352 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.3610 \n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.3303 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.3157 \n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.3273 \n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.2628 \n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.3063 \n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.3065 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9725 - loss: 0.2472 \n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9700 - loss: 0.2820 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.2904 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.2739 \n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.2386 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.2369 \n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.2270 \n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9571 - loss: 0.2400 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.2249 \n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.2297 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.2155 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.2016 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.1808 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.2048 \n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.1864 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.1642 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.1790 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.1847 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.1712 \n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.1818 \n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.1611 \n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.1486 \n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.1505 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9667 - loss: 0.2080\n",
            "Akurasi: 0.9666666388511658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tugas 3"
      ],
      "metadata": {
        "id": "uGy5pWZ9_J7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Akurasi meningkat signifikan saat menggunakan ReLU (96%) dibandingkan Sigmoid (56%) karena ReLU lebih efektif dalam proses pembelajaran jaringan modern. ReLU tidak mengalami masalah vanishing gradient seperti Sigmoid, sehingga gradien tetap kuat dan model dapat belajar lebih cepat serta lebih stabil. Sebaliknya, Sigmoid cenderung membuat pembaruan bobot menjadi sangat kecil, sehingga proses belajar lambat dan performa akhir lebih rendah. Akibatnya, ReLU mampu menangkap pola pada dataset Iris dengan jauh lebih baik."
      ],
      "metadata": {
        "id": "trKnM-FQBcAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Bangun model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(12, activation='sigmoid', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(10, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi: {acc}\")"
      ],
      "metadata": {
        "id": "ExFHGF1L_JWF",
        "outputId": "d815bbce-73b7-4bf1-e731-cd66cfcb3f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3640 - loss: 1.1591\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4040 - loss: 1.1106 \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3961 - loss: 1.1059 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3484 - loss: 1.1136 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3096 - loss: 1.1160 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3227 - loss: 1.1066 \n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3786 - loss: 1.0850 \n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3531 - loss: 1.0771 \n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6041 - loss: 1.0605 \n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6103 - loss: 1.0821 \n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 1.0488 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 1.0541 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7030 - loss: 1.0415 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6944 - loss: 1.0323 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6508 - loss: 1.0288 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7063 - loss: 1.0191 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7547 - loss: 0.9937 \n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6983 - loss: 0.9892 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7186 - loss: 0.9872 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7152 - loss: 0.9675 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6691 - loss: 0.9894 \n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7281 - loss: 0.9509 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6505 - loss: 0.9570\n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.9346 \n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7075 - loss: 0.9210 \n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7146 - loss: 0.8916 \n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6885 - loss: 0.9032 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6480 - loss: 0.8748\n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7097 - loss: 0.8661 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6959 - loss: 0.8266 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6600 - loss: 0.8370\n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6180 - loss: 0.8298 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7156 - loss: 0.7946\n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6724 - loss: 0.8119 \n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7035 - loss: 0.7535 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7399 - loss: 0.7240\n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6821 - loss: 0.7375 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7247 - loss: 0.7055 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6528 - loss: 0.6985 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6617 - loss: 0.6599 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7403 - loss: 0.6292\n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.6347 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6844 - loss: 0.6628 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6844 - loss: 0.6612 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6806 - loss: 0.6657 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7128 - loss: 0.5967 \n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 0.5702 \n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 0.5878 \n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6852 - loss: 0.6051 \n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6509 - loss: 0.5660 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.5667 - loss: 0.5842\n",
            "Akurasi: 0.5666666626930237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Praktikum 3\n"
      ],
      "metadata": {
        "id": "XC5ohcOMB622"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Contoh dataset (buat dummy data)\n",
        "data = pd.DataFrame({\n",
        "    'luas': [50, 60, 70, 80, 90],\n",
        "    'harga': [500, 600, 700, 800, 900]\n",
        "})\n",
        "\n",
        "X = data[['luas']]\n",
        "y = data[['harga']]\n",
        "\n",
        "# Normalisasi\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X_train, y_train, epochs=100)\n",
        "\n",
        "# Evaluasi\n",
        "print(\"Prediksi:\", model.predict(X_test))"
      ],
      "metadata": {
        "id": "WVdAmg1xB9AU",
        "outputId": "d69c82f5-b668-47b7-98ae-a01f4557e5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 1.1516\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.1390\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.1264\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.1139\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.1016\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.0893\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.0771\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 1.0650\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.0530\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.0411\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.0293\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.0180\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.0069\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9958\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.9849\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9745\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9645\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.9546\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9448\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.9350\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9253\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.9157\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9062\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.8971\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8881\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8792\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.8704\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8617\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8531\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.8445\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8360\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8276\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8193\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.8118\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.8045\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.7973\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.7901\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.7830\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7759\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.7688\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.7618\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.7549\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.7480\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7412\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.7344\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7276\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.7209\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7142\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.7076\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.7010\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.6945\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6880\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6816\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6751\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6688\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6625\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6562\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6500\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6438\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6376\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6315\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6255\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.6195\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.6135\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.6075\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6016\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5958\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.5899\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5842\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5784\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.5727\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5671\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5614\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.5558\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.5503\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5448\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5393\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5339\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.5285\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5231\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5178\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.5125\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.5072\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5020\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4968\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4917\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4865\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4815\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4764\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4714\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4664\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4615\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4566\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4517\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4469\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4421\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.4373\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4326\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4279\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4232\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "Prediksi: [[0.69494265]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas 4\n"
      ],
      "metadata": {
        "id": "IHZCGUGdDA8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sebelum mengubah learning rate**\n",
        "\n",
        "Loss awal: 1.15\n",
        "\n",
        "Loss akhir: 0.42\n",
        "\n",
        "Prediksi: 0.6949\n",
        "\n",
        "Learning rate default Adam (0.001) membuat proses training stabil tetapi lambat. Loss turun perlahan dari epoch 1 hingga 100.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Sesudah mengubah learning rate**\n",
        "\n",
        "Loss awal: 2.36\n",
        "\n",
        "Loss akhir: 0.0059\n",
        "\n",
        "Prediksi: 0.8584\n",
        "\n",
        "Learning rate yang lebih besar membuat training lebih cepat dan loss turun drastis. Dalam 100 epoch loss mencapai nilai yang jauh lebih rendah dibanding sebelumnya."
      ],
      "metadata": {
        "id": "xcG7FBHCDCmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Contoh dataset (dummy data)\n",
        "data = pd.DataFrame({\n",
        "    'luas': [50, 60, 70, 80, 90],\n",
        "    'harga': [500, 600, 700, 800, 900]\n",
        "})\n",
        "\n",
        "X = data[['luas']]\n",
        "y = data[['harga']]\n",
        "\n",
        "# Normalisasi\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100)\n",
        "\n",
        "# Evaluasi\n",
        "print(\"Prediksi:\", model.predict(X_test))\n"
      ],
      "metadata": {
        "id": "-PSBG05YCD__",
        "outputId": "b028ae74-3724-4988-8893-76c99aacc895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 2.3645\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.1915\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 2.0414\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.9024\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 1.7740\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.6557\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.5440\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.4421\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.3466\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.2577\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.1757\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.0983\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.0252\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9605\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9022\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.8452\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.7897\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7387\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.6893\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.6415\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.5944\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.5490\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.5056\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.4640\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4244\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3869\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3515\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3187\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2880\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2593\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2326\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2078\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.1849\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1638\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.1444\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1267\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1105\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0958\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0826\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0711\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0613\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0526\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0449\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0380\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0321\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0270\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0227\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0192\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0164\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0143\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0127\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0118\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0113\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0111\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0113\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0116\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0121\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0126\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0131\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0136\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0139\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0141\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0141\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0140\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0138\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0135\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0131\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0126\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0121\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0115\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0110\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0105\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0100\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0095\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0091\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0087\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0083\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0080\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0077\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0074\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0072\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0070\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0068\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0067\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0065\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0064\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0064\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0063\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0063\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0062\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0062\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0062\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0062\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0061\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0061\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0061\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0060\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0060\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0060\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0059\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Prediksi: [[0.8584529]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 1. Load\n",
        "data = fetch_california_housing()\n",
        "X = data.data; y = data.target\n",
        "\n",
        "# 2. Preprocess\n",
        "scaler = StandardScaler(); Xs = scaler.fit_transform(X)\n",
        "X_train, X_val, y_train, y_val = train_test_split(Xs, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Build model\n",
        "model = Sequential([\n",
        "Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "Dense(32, activation='relu'),\n",
        "Dense(1)\n",
        "])\n",
        "model.compile(optimizer=Adam(1e-3), loss='mse', metrics=['mae'])\n",
        "\n",
        "# 4. Train\n",
        "h = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32, verbose=0)\n",
        "\n",
        "# 5. Plot\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1); plt.plot(h.history['loss'], label='train_loss'); plt.plot(h.history['val_loss'], label='val_loss'); plt.legend(); plt.title('MSE')\n",
        "plt.subplot(1,2,2); plt.plot(h.history['mae'], label='train_mae'); plt.plot(h.history['val_mae'], label='val_mae'); plt.legend(); plt.title('MAE')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "pred = model.predict(X_val)\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_val, pred)))"
      ],
      "metadata": {
        "id": "5dyJ6-JlDzrV",
        "outputId": "c68db892-3d2f-4a1c-bf8b-41956c3143af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "RMSE: 0.5148289628362303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tugas Praktikum"
      ],
      "metadata": {
        "id": "4L_nzuDRPNCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ubah jumlah neuron di hidden layer (misal: 256 dan 128)."
      ],
      "metadata": {
        "id": "4GWLQo3lPgiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), # Ubah gambar 28x28 menjadi vektor\n",
        "    Dense(128, activation='relu'), # Hidden layer 1\n",
        "    Dense(64, activation='relu'),  # Hidden layer 2\n",
        "    Dense(10, activation='softmax') # Output layer (10 kelas)\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Latih model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")\n",
        ""
      ],
      "metadata": {
        "id": "c9fI1_P9OZ1z",
        "outputId": "68d4b7aa-0d70-4096-a4e7-b78500cfe81b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8783 - loss: 0.4134 - val_accuracy: 0.9673 - val_loss: 0.1058\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9686 - loss: 0.1045 - val_accuracy: 0.9705 - val_loss: 0.0959\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9787 - loss: 0.0688 - val_accuracy: 0.9741 - val_loss: 0.0851\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0488 - val_accuracy: 0.9739 - val_loss: 0.0827\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0384 - val_accuracy: 0.9754 - val_loss: 0.0788\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9893 - loss: 0.0312 - val_accuracy: 0.9786 - val_loss: 0.0739\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0243 - val_accuracy: 0.9792 - val_loss: 0.0768\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9931 - loss: 0.0220 - val_accuracy: 0.9780 - val_loss: 0.0886\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0188 - val_accuracy: 0.9743 - val_loss: 0.1038\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0177 - val_accuracy: 0.9775 - val_loss: 0.0970\n",
            "Akurasi pada data uji: 0.9775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambahkan satu hidden layer lagi.\n",
        "\n"
      ],
      "metadata": {
        "id": "I7wNZkH-Phlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), # Ubah gambar 28x28 menjadi vektor\n",
        "    Dense(128, activation='relu'), # Hidden layer 1\n",
        "    Dense(64, activation='relu'),  # Hidden layer 2\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax') # Output layer (10 kelas)\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Latih model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "wajVhNLMPTbS",
        "outputId": "dcd5b4da-4fa3-425f-d6ca-1b91b2488431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8633 - loss: 0.4526 - val_accuracy: 0.9585 - val_loss: 0.1267\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.1093 - val_accuracy: 0.9700 - val_loss: 0.0966\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9759 - loss: 0.0742 - val_accuracy: 0.9730 - val_loss: 0.0859\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0534 - val_accuracy: 0.9715 - val_loss: 0.0922\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.0442 - val_accuracy: 0.9770 - val_loss: 0.0814\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0347 - val_accuracy: 0.9760 - val_loss: 0.0907\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0299 - val_accuracy: 0.9769 - val_loss: 0.0867\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0244 - val_accuracy: 0.9682 - val_loss: 0.1262\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0243 - val_accuracy: 0.9777 - val_loss: 0.0983\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0185 - val_accuracy: 0.9759 - val_loss: 0.1014\n",
            "Akurasi pada data uji: 0.9759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bandingkan akurasi dan waktu pelatihan.\n",
        "\n",
        "1. Sebelum Menambah Hidden Layer\n",
        "\n",
        "Akurasi: 0.9775\n",
        "Model dengan dua hidden layer (128 → 64) sudah cukup optimal.\n",
        "Loss dan akurasi stabil, tidak terjadi overfitting yang signifikan.\n",
        "\n",
        "2. Setelah Menambah Satu Hidden Layer\n",
        "\n",
        "(Hidden layer menjadi: 128 → 64 → 32)\n",
        "Akurasi: 0.9759\n",
        "\n",
        "Hasilnya justru sedikit menurun dibandingkan model awal."
      ],
      "metadata": {
        "id": "kJu8wdxBPmyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Fungsi untuk training + hitung waktu\n",
        "def train_model(activation):\n",
        "    print(f\"\\n===== Model dengan aktivasi {activation.upper()} =====\")\n",
        "\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(128, activation=activation),\n",
        "        Dense(64, activation=activation),\n",
        "        Dense(32, activation=activation),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    start = time.time()\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "    end = time.time()\n",
        "\n",
        "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Akurasi : {acc:.4f}\")\n",
        "    print(f\"Waktu   : {end - start:.2f} detik\")\n",
        "\n",
        "    return acc, end - start\n",
        "\n",
        "# 2. Eksperimen ReLU\n",
        "relu_acc, relu_time = train_model('relu')\n",
        "\n",
        "# 3. Eksperimen Sigmoid\n",
        "sig_acc, sig_time = train_model('sigmoid')\n",
        "\n",
        "# 4. Ringkasan hasil\n",
        "print(\"\\n================ RINGKASAN PERBANDINGAN ================\")\n",
        "print(f\"ReLU    → Akurasi: {relu_acc:.4f}, Waktu: {relu_time:.2f} detik\")\n",
        "print(f\"Sigmoid → Akurasi: {sig_acc:.4f}, Waktu: {sig_time:.2f} detik\")\n"
      ],
      "metadata": {
        "id": "x2sILHulPLTx",
        "outputId": "06dbc639-6a87-4013-f3e2-dcd102b72785",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Model dengan aktivasi RELU =====\n",
            "Akurasi : 0.9768\n",
            "Waktu   : 90.61 detik\n",
            "\n",
            "===== Model dengan aktivasi SIGMOID =====\n",
            "Akurasi : 0.9741\n",
            "Waktu   : 89.16 detik\n",
            "\n",
            "================ RINGKASAN PERBANDINGAN ================\n",
            "ReLU    → Akurasi: 0.9768, Waktu: 90.61 detik\n",
            "Sigmoid → Akurasi: 0.9741, Waktu: 89.16 detik\n"
          ]
        }
      ]
    }
  ]
}